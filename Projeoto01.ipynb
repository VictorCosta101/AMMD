{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A transferência de conhecimento (ou Transfer Learning) é uma técnica poderosa no campo do deep learning que permite utilizar o conhecimento adquirido em uma tarefa anterior para melhorar o desempenho em uma nova tarefa relacionada. Essa abordagem é particularmente útil quando os dados disponíveis para a nova tarefa são limitados ou quando o treinamento do modelo do zero seria computacionalmente caro e demorado.\n",
        "Conceitos Fundamentais\n",
        "# 1. Definição\n",
        "\n",
        "Transfer Learning é a prática de reutilizar um modelo treinado previamente em uma tarefa similar como ponto de partida para uma nova tarefa. Em vez de treinar um modelo desde o início, você ajusta um modelo pré-treinado para atender aos requisitos específicos da nova tarefa.\n",
        "# 2. Motivação\n",
        "\n",
        "    Escassez de Dados: Muitas vezes, a nova tarefa pode não ter uma quantidade suficiente de dados rotulados para treinar um modelo eficaz.\n",
        "    Recursos Computacionais: Treinar um modelo do zero pode ser intensivo em termos de recursos e tempo.\n",
        "    Desempenho Melhorado: Modelos pré-treinados geralmente capturam características relevantes que podem ser úteis para a nova tarefa, resultando em um desempenho melhorado.\n",
        "\n",
        "Aplicações de Transfer Learning\n",
        "1. Visão Computacional\n",
        "\n",
        "    Classificação de Imagens: Modelos como VGG, ResNet e Inception são frequentemente pré-treinados em grandes datasets como o ImageNet e, em seguida, ajustados para tarefas específicas, como classificação de imagens médicas ou reconhecimento de objetos.\n",
        "    Detecção de Objetos: Modelos pré-treinados podem ser adaptados para identificar e localizar objetos em imagens específicas.\n",
        "\n",
        "2. Processamento de Linguagem Natural (NLP)\n",
        "\n",
        "    Análise de Sentimentos: Modelos como GPT, pré-treinados em grandes corpora de texto, podem ser ajustados para tarefas específicas, como análise de sentimentos ou tradução automática.\n",
        "    Classificação de Textos: Transferência de modelos pré-treinados para categorizar documentos em diferentes tópicos.\n",
        "\n",
        "Estratégias de Transfer Learning\n",
        "1. Feature Extraction\n",
        "\n",
        "Nesta abordagem, você usa a rede pré-treinada como extrator de características. As camadas iniciais do modelo pré-treinado são fixas e apenas as últimas camadas são treinadas novamente com os dados da nova tarefa.\n",
        "2. Fine-Tuning\n",
        "\n",
        "Aqui, todas as camadas do modelo pré-treinado são ajustadas, mas o treinamento começa a partir dos pesos do modelo pré-treinado em vez de pesos aleatórios. Isso permite que o modelo se adapte melhor à nova tarefa enquanto retém o conhecimento prévio.\n",
        "3. Modelos Pré-Treinados Específicos\n",
        "\n",
        "Existem modelos pré-treinados disponíveis para tarefas específicas. Por exemplo, modelos pré-treinados em reconhecimento facial podem ser utilizados como base para construir sistemas de segurança ou de identificação.\n",
        "Vantagens e Desvantagens\n",
        "Vantagens\n",
        "\n",
        "    Economia de Tempo e Recursos: Reduz significativamente o tempo de treinamento e os requisitos computacionais.\n",
        "    Melhor Desempenho: Aproveita o conhecimento adquirido em grandes datasets e pode melhorar o desempenho em tarefas com poucos dados.\n",
        "    Flexibilidade: Pode ser aplicado em diversas áreas, desde visão computacional até processamento de linguagem natural.\n",
        "\n",
        "Desvantagens\n",
        "\n",
        "    Dependência de Dados Originais: O desempenho pode ser limitado se os dados da nova tarefa forem muito diferentes dos dados usados para treinar o modelo original.\n",
        "    Overfitting: Pode ocorrer overfitting se o modelo pré-treinado for muito específico para a nova tarefa sem ajustes adequados.\n",
        "\n",
        "Exemplo Prático\n",
        "\n",
        "Um exemplo prático de Transfer Learning é a adaptação de um modelo ResNet, pré-treinado no dataset ImageNet, para a classificação de imagens.\n",
        "\n",
        "    Carregar o Modelo Pré-Treinado: Utilize uma implementação do ResNet disponível em frameworks como TensorFlow ou PyTorch.\n",
        "    Congelar Camadas Iniciais: Mantenha as camadas iniciais do modelo, que aprendem características básicas como bordas e texturas, congeladas.\n",
        "    Adicionar Camadas Personalizadas: Adicione camadas específicas para a nova tarefa de classificação das imagens.\n",
        "   Avião\n",
        "Automóvel\n",
        "Pássaro\n",
        "Gato\n",
        "Cervo\n",
        "Cachorro\n",
        "Sapo\n",
        "Cavalo\n",
        "Navio\n",
        "Caminhão."
      ],
      "metadata": {
        "id": "seokvBggvk-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Carregar o dataset CIFAR-10\n",
        "(train_data, train_labels), (val_data, val_labels) = cifar10.load_data()\n",
        "\n",
        "# Normalizar os dados\n",
        "train_data = train_data.astype('float32') / 255.0\n",
        "val_data = val_data.astype('float32') / 255.0\n",
        "\n",
        "# Converter as labels para one-hot encoding\n",
        "train_labels = to_categorical(train_labels, num_classes=10)\n",
        "val_labels = to_categorical(val_labels, num_classes=10)\n",
        "\n",
        "# Carregar o modelo ResNet50 pré-treinado\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Congelar as camadas convolucionais do modelo pré-treinado\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Adicionar camadas personalizadas para classificação\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)  # 10 classes no CIFAR-10\n",
        "\n",
        "# Criar o novo modelo\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compilar o modelo\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinar o modelo com os dados de CIFAR-10\n",
        "model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izIPgCQx8Svi",
        "outputId": "00b7feca-6565-4543-fe8e-cfc5f3e6223a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 32s 16ms/step - loss: 2.0513 - accuracy: 0.2534 - val_loss: 1.9174 - val_accuracy: 0.3022\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 1.8802 - accuracy: 0.3155 - val_loss: 2.0186 - val_accuracy: 0.2843\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 1.8262 - accuracy: 0.3348 - val_loss: 1.8305 - val_accuracy: 0.3310\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 1.7875 - accuracy: 0.3550 - val_loss: 1.7777 - val_accuracy: 0.3625\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 1.7631 - accuracy: 0.3635 - val_loss: 1.8355 - val_accuracy: 0.3340\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 23s 15ms/step - loss: 1.7482 - accuracy: 0.3694 - val_loss: 1.7102 - val_accuracy: 0.3856\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 1.7301 - accuracy: 0.3758 - val_loss: 1.7629 - val_accuracy: 0.3699\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.7232 - accuracy: 0.3803 - val_loss: 1.6958 - val_accuracy: 0.3904\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 23s 15ms/step - loss: 1.7093 - accuracy: 0.3843 - val_loss: 1.7594 - val_accuracy: 0.3712\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 1.7017 - accuracy: 0.3872 - val_loss: 1.6731 - val_accuracy: 0.4034\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7806505c9d50>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}